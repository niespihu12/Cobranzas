"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš ï¸  ENTRENADOR DE MODELO XGBOOST - SOLO PARA DEMOSTRACIÃ“N  âš ï¸               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  Este script entrena un modelo XGBoost usando datos SIMULADOS.                â•‘
â•‘                                                                               â•‘
â•‘  â€¢ El modelo NO refleja el comportamiento real de clientes                    â•‘
â•‘  â€¢ Las predicciones son para DEMOSTRACIÃ“N tÃ©cnica Ãºnicamente                  â•‘
â•‘  â€¢ NO usar en producciÃ³n sin datos histÃ³ricos reales                          â•‘
â•‘                                                                               â•‘
â•‘  Autor: Equipo de Inteligencia Voicebot                                       â•‘
â•‘  Fecha: Enero 2026                                                            â•‘
â•‘  VersiÃ³n: 1.0                                                                 â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Importar librerÃ­as de ML
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report,
    roc_curve
)
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
import pickle

# ============================================================================
# CONFIGURACIÃ“N
# ============================================================================

CONFIG = {
    'test_size': 0.20,          # 20% para test
    'random_state': 42,         # Reproducibilidad
    'modelo_output': '../02_datos/salida/modelo_xgboost_SIMULADO.pkl',
    'metricas_output': '../02_datos/salida/metricas_modelo_SIMULADO.txt',
}

# ParÃ¡metros de XGBoost
XGBOOST_PARAMS = {
    'n_estimators': 100,        # NÃºmero de Ã¡rboles
    'max_depth': 5,             # Profundidad mÃ¡xima de cada Ã¡rbol
    'learning_rate': 0.1,       # Tasa de aprendizaje
    'subsample': 0.8,           # Porcentaje de datos por Ã¡rbol
    'colsample_bytree': 0.8,    # Porcentaje de features por Ã¡rbol
    'random_state': 42,
    'eval_metric': 'auc',
    'use_label_encoder': False,
}

# ============================================================================
# FUNCIONES
# ============================================================================

def preparar_datos(df):
    """
    Prepara los datos para entrenamiento.
    
    - Selecciona features relevantes
    - Convierte categÃ³ricas a numÃ©ricas
    - Maneja valores nulos
    """
    print("\n1ï¸âƒ£ Preparando datos...")
    
    # Features a usar
    features = [
        'dias_mora_al_momento',
        'saldo_mora_al_momento',
        'tenia_campana',
        'requeria_pago',
        'descuento_ofrecido',
        'canal',
        'hora_gestion',
        'intento_numero',
        'producto',
    ]
    
    # Target
    target = 'pago_realizado'
    
    # Copiar solo las columnas necesarias
    df_ml = df[features + [target]].copy()
    
    # Convertir hora a nÃºmero (extraer solo la hora)
    df_ml['hora_num'] = df_ml['hora_gestion'].apply(
        lambda x: int(str(x).split(':')[0]) if pd.notna(x) else 12
    )
    df_ml = df_ml.drop('hora_gestion', axis=1)
    
    # Convertir booleanos a int
    df_ml['tenia_campana'] = df_ml['tenia_campana'].astype(int)
    df_ml['requeria_pago'] = df_ml['requeria_pago'].astype(int)
    df_ml['pago_realizado'] = df_ml['pago_realizado'].astype(int)
    
    # Convertir categÃ³ricas con LabelEncoder
    le_canal = LabelEncoder()
    df_ml['canal_encoded'] = le_canal.fit_transform(df_ml['canal'].fillna('Desconocido'))
    
    le_producto = LabelEncoder()
    df_ml['producto_encoded'] = le_producto.fit_transform(df_ml['producto'].fillna('Desconocido'))
    
    # Manejar nulos en descuento
    df_ml['descuento_ofrecido'] = df_ml['descuento_ofrecido'].fillna(0)
    
    # Seleccionar features finales
    features_finales = [
        'dias_mora_al_momento',
        'saldo_mora_al_momento',
        'tenia_campana',
        'requeria_pago',
        'descuento_ofrecido',
        'canal_encoded',
        'hora_num',
        'intento_numero',
        'producto_encoded',
    ]
    
    X = df_ml[features_finales]
    y = df_ml[target]
    
    print(f"   âœ“ Features: {len(features_finales)}")
    print(f"   âœ“ Registros: {len(X):,}")
    print(f"   âœ“ Target 'pago_realizado': {y.sum():,} positivos ({100*y.mean():.1f}%)")
    
    # Guardar encoders para uso posterior
    encoders = {
        'canal': le_canal,
        'producto': le_producto,
        'features': features_finales
    }
    
    return X, y, encoders


def entrenar_modelo(X_train, y_train, X_test, y_test):
    """
    Entrena el modelo XGBoost.
    """
    print("\n2ï¸âƒ£ Entrenando modelo XGBoost...")
    print(f"   â€¢ Ãrboles: {XGBOOST_PARAMS['n_estimators']}")
    print(f"   â€¢ Profundidad mÃ¡xima: {XGBOOST_PARAMS['max_depth']}")
    print(f"   â€¢ Learning rate: {XGBOOST_PARAMS['learning_rate']}")
    
    # Crear modelo
    modelo = xgb.XGBClassifier(**XGBOOST_PARAMS)
    
    # Entrenar
    modelo.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=False
    )
    
    print("   âœ“ Modelo entrenado")
    
    return modelo


def evaluar_modelo(modelo, X_test, y_test):
    """
    EvalÃºa el modelo y genera mÃ©tricas.
    """
    print("\n3ï¸âƒ£ Evaluando modelo...")
    
    # Predicciones
    y_pred = modelo.predict(X_test)
    y_pred_proba = modelo.predict_proba(X_test)[:, 1]
    
    # MÃ©tricas
    metricas = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred),
        'recall': recall_score(y_test, y_pred),
        'f1': f1_score(y_test, y_pred),
        'auc_roc': roc_auc_score(y_test, y_pred_proba),
    }
    
    # Matriz de confusiÃ³n
    cm = confusion_matrix(y_test, y_pred)
    
    # Reporte de clasificaciÃ³n
    reporte = classification_report(y_test, y_pred, target_names=['No Paga', 'Paga'])
    
    return metricas, cm, reporte, y_pred_proba


def obtener_importancia_variables(modelo, features):
    """
    Obtiene la importancia de cada variable.
    """
    importancia = pd.DataFrame({
        'feature': features,
        'importancia': modelo.feature_importances_
    }).sort_values('importancia', ascending=False)
    
    return importancia


def generar_reporte(metricas, cm, reporte, importancia, X_train, X_test):
    """
    Genera un reporte completo en texto.
    """
    linea = "=" * 70
    
    texto = f"""
{linea}
âš ï¸  REPORTE DE MODELO XGBOOST - DATOS SIMULADOS - SOLO DEMOSTRACIÃ“N  âš ï¸
{linea}

Fecha de generaciÃ³n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{linea}
1. RESUMEN DEL DATASET
{linea}

â€¢ Registros de entrenamiento: {len(X_train):,}
â€¢ Registros de prueba: {len(X_test):,}
â€¢ Total: {len(X_train) + len(X_test):,}
â€¢ DivisiÃ³n: 80% entrenamiento / 20% prueba

{linea}
2. MÃ‰TRICAS DE RENDIMIENTO
{linea}

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      MÃ©trica       â•‘     Valor     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ AUC-ROC            â•‘    {metricas['auc_roc']:.4f}      â•‘
â•‘ Accuracy           â•‘    {metricas['accuracy']:.4f}      â•‘
â•‘ PrecisiÃ³n          â•‘    {metricas['precision']:.4f}      â•‘
â•‘ Recall             â•‘    {metricas['recall']:.4f}      â•‘
â•‘ F1-Score           â•‘    {metricas['f1']:.4f}      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

InterpretaciÃ³n:
â€¢ AUC-ROC {metricas['auc_roc']:.2f}: {"Excelente" if metricas['auc_roc'] >= 0.9 else "Muy bueno" if metricas['auc_roc'] >= 0.8 else "Bueno" if metricas['auc_roc'] >= 0.7 else "Regular"} capacidad de discriminaciÃ³n
â€¢ PrecisiÃ³n {metricas['precision']:.2f}: De cada 100 que predice como "paga", {int(metricas['precision']*100)} realmente pagan
â€¢ Recall {metricas['recall']:.2f}: De cada 100 que realmente pagan, identifica {int(metricas['recall']*100)}

{linea}
3. MATRIZ DE CONFUSIÃ“N
{linea}

                    PredicciÃ³n
                 No Paga    Paga
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Realidad      â”‚          â”‚          â”‚
  No Paga     â”‚  {cm[0][0]:>6,}  â”‚  {cm[0][1]:>6,}  â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  Paga        â”‚  {cm[1][0]:>6,}  â”‚  {cm[1][1]:>6,}  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â€¢ Verdaderos Negativos (No paga â†’ Predijo No paga): {cm[0][0]:,}
â€¢ Falsos Positivos (No paga â†’ Predijo Paga): {cm[0][1]:,}
â€¢ Falsos Negativos (Paga â†’ Predijo No paga): {cm[1][0]:,}
â€¢ Verdaderos Positivos (Paga â†’ Predijo Paga): {cm[1][1]:,}

{linea}
4. REPORTE DE CLASIFICACIÃ“N DETALLADO
{linea}

{reporte}

{linea}
5. IMPORTANCIA DE VARIABLES
{linea}

Â¿QuÃ© factores influyen mÃ¡s en la predicciÃ³n de pago?

"""
    
    # Agregar importancia de variables con barras visuales
    max_imp = importancia['importancia'].max()
    for _, row in importancia.iterrows():
        barra_len = int(30 * row['importancia'] / max_imp)
        barra = "â–ˆ" * barra_len
        texto += f"  {row['feature']:<25} {barra} {row['importancia']:.4f} ({100*row['importancia']:.1f}%)\n"
    
    texto += f"""

{linea}
6. PARÃMETROS DEL MODELO
{linea}

â€¢ Algoritmo: XGBoost (Gradient Boosting)
â€¢ NÃºmero de Ã¡rboles: {XGBOOST_PARAMS['n_estimators']}
â€¢ Profundidad mÃ¡xima: {XGBOOST_PARAMS['max_depth']}
â€¢ Learning rate: {XGBOOST_PARAMS['learning_rate']}
â€¢ Subsample: {XGBOOST_PARAMS['subsample']}
â€¢ Colsample by tree: {XGBOOST_PARAMS['colsample_bytree']}

{linea}
âš ï¸  ADVERTENCIA IMPORTANTE
{linea}

Este modelo fue entrenado con DATOS SIMULADOS.

â€¢ Las mÃ©tricas NO reflejan el rendimiento real que tendrÃ­a con datos del banco
â€¢ Las probabilidades de pago son FICTICIAS
â€¢ La importancia de variables puede ser diferente con datos reales

USAR SOLO PARA:
âœ… DemostraciÃ³n tÃ©cnica
âœ… Pruebas de integraciÃ³n
âœ… CapacitaciÃ³n del equipo

NO USAR PARA:
âŒ Decisiones de negocio reales
âŒ ProducciÃ³n
âŒ Reportes oficiales

{linea}
"""
    
    return texto


# ============================================================================
# EJECUCIÃ“N PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    print("\n" + "â•”" + "â•" * 68 + "â•—")
    print("â•‘" + " âš ï¸  ENTRENAMIENTO DE MODELO XGBOOST - DATOS SIMULADOS ".center(68) + "â•‘")
    print("â•š" + "â•" * 68 + "â•")
    
    # Cargar histÃ³rico simulado
    print("\nðŸ“‚ Cargando histÃ³rico simulado...")
    df = pd.read_excel('../02_datos/salida/historico_gestiones_SIMULADO.xlsx')
    print(f"   âœ“ {len(df):,} registros cargados")
    
    # Preparar datos
    X, y, encoders = preparar_datos(df)
    
    # Dividir en train/test
    print("\n   Dividiendo datos 80/20...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=CONFIG['test_size'],
        random_state=CONFIG['random_state'],
        stratify=y  # Mantener proporciÃ³n de clases
    )
    print(f"   âœ“ Entrenamiento: {len(X_train):,} registros")
    print(f"   âœ“ Prueba: {len(X_test):,} registros")
    
    # Entrenar modelo
    modelo = entrenar_modelo(X_train, y_train, X_test, y_test)
    
    # Evaluar modelo
    metricas, cm, reporte, y_pred_proba = evaluar_modelo(modelo, X_test, y_test)
    
    # Importancia de variables
    print("\n4ï¸âƒ£ Calculando importancia de variables...")
    importancia = obtener_importancia_variables(modelo, encoders['features'])
    print("   âœ“ Importancia calculada")
    
    # Mostrar mÃ©tricas en consola
    print("\n" + "=" * 70)
    print("ðŸ“Š MÃ‰TRICAS DEL MODELO")
    print("=" * 70)
    print(f"\n   AUC-ROC:    {metricas['auc_roc']:.4f}")
    print(f"   Accuracy:   {metricas['accuracy']:.4f}")
    print(f"   PrecisiÃ³n:  {metricas['precision']:.4f}")
    print(f"   Recall:     {metricas['recall']:.4f}")
    print(f"   F1-Score:   {metricas['f1']:.4f}")
    
    print("\nðŸ“Š IMPORTANCIA DE VARIABLES (Top 5):")
    for i, (_, row) in enumerate(importancia.head().iterrows()):
        print(f"   {i+1}. {row['feature']}: {100*row['importancia']:.1f}%")
    
    # Guardar modelo
    print(f"\n5ï¸âƒ£ Guardando modelo...")
    modelo_guardado = {
        'modelo': modelo,
        'encoders': encoders,
        'metricas': metricas,
        'importancia': importancia,
        'fecha_entrenamiento': datetime.now().isoformat(),
        'advertencia': 'MODELO ENTRENADO CON DATOS SIMULADOS - SOLO DEMOSTRACIÃ“N'
    }
    
    with open(CONFIG['modelo_output'], 'wb') as f:
        pickle.dump(modelo_guardado, f)
    print(f"   âœ“ Modelo guardado en: {CONFIG['modelo_output']}")
    
    # Generar y guardar reporte
    print(f"\n6ï¸âƒ£ Generando reporte...")
    reporte_texto = generar_reporte(metricas, cm, reporte, importancia, X_train, X_test)
    
    with open(CONFIG['metricas_output'], 'w') as f:
        f.write(reporte_texto)
    print(f"   âœ“ Reporte guardado en: {CONFIG['metricas_output']}")
    
    print("\n" + "=" * 70)
    print("âœ… ENTRENAMIENTO COMPLETADO")
    print("=" * 70)
    print("\nâš ï¸  RECUERDA: Este modelo usa datos SIMULADOS, solo para demostraciÃ³n.")
    print("=" * 70)
